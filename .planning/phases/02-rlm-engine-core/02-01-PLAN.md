---
phase: 02-rlm-engine-core
plan: 01
type: execute
wave: 1
depends_on: []
files_modified: [src/rlm/engine/types.ts, src/rlm/engine/state.ts, src/rlm/engine/index.ts]
autonomous: true
---

<objective>
Extend RLM types and implement REPL-style state management for the RLM engine.

Purpose: Foundation types and state container that all other Phase 2 modules depend on.
Output: RLMState class with variable storage, context management, and recursion tracking.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-rlm-engine-core/02-RESEARCH.md

# Existing types from Phase 1
@src/rlm/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create engine-specific types</name>
  <files>src/rlm/engine/types.ts</files>
  <action>
Create src/rlm/engine/ directory and types.ts with RLM engine types:

```typescript
/**
 * RLM Engine Types
 *
 * Types specific to the recursive reasoning engine.
 * Extends core types from ../types.ts
 */

import type { Chunk, SearchResult } from '../types.js';

/**
 * Evidence linking a claim to source chunks
 */
export interface Evidence {
  claim: string;           // The statement being made
  sourceChunks: string[];  // Chunk IDs that support it
  confidence: number;      // 0-1 based on retrieval scores
  verified: boolean;       // Post-verification status
}

/**
 * Result from an RLM query
 */
export interface RLMResult {
  response: string;
  evidence: Evidence[];
  reasoning: string[];     // Chain of thought steps
  tokensUsed: number;
  depth: number;
  verified: boolean;
  canRecurse: boolean;
  refinedQuery?: string;   // For recursion
}

/**
 * Engine configuration
 */
export interface RLMEngineConfig {
  model: string;
  maxDepth: number;
  tokenBudget: number;
  confidenceThreshold: number;
}

export const DEFAULT_ENGINE_CONFIG: RLMEngineConfig = {
  model: 'llama3.1:8b',
  maxDepth: 5,
  tokenBudget: 16000,  // 2x typical response budget
  confidenceThreshold: 0.7,
};

/**
 * Tool call from LLM
 */
export interface ToolCall {
  function: {
    name: string;
    arguments: Record<string, unknown>;
  };
}

/**
 * Final answer from tool call
 */
export interface FinalAnswer {
  answer: string;
  evidence: string[];
  confidence: number;
}

/**
 * Context chunk for state
 */
export interface ContextChunk {
  id: string;
  text: string;
  score: number;  // Retrieval score
  metadata: {
    path: string;
    symbol_name: string;
    start_line: number;
    end_line: number;
  };
}
```

Key types:
- Evidence: Links claims to source chunks (RLM-03)
- RLMResult: Output with evidence, reasoning, tokens (RLM-01)
- RLMEngineConfig: Configuration with limits (RLM-05)
  </action>
  <verify>npm run build:rlm compiles types</verify>
  <done>Engine types defined</done>
</task>

<task type="auto">
  <name>Task 2: Implement REPL-style state management</name>
  <files>src/rlm/engine/state.ts</files>
  <action>
Create state.ts implementing the REPL-style state container:

```typescript
/**
 * RLM State Management
 *
 * REPL-style state container for the RLM engine.
 * Stores context as named variables - LLM inspects via tools, not direct prompt.
 */

import type { Evidence, ContextChunk, RLMEngineConfig, DEFAULT_ENGINE_CONFIG } from './types.js';
import type { Chunk } from '../types.js';

/**
 * State container for RLM execution
 */
export interface RLMStateData {
  variables: Map<string, unknown>;
  chunks: ContextChunk[];     // Retrieved chunks (stored, not in prompt)
  query: string;              // Current query
  originalQuery: string;      // Initial query for tracking
  depth: number;              // Recursion depth
  tokenBudget: number;        // Remaining tokens
  tokensUsed: number;         // Tokens consumed so far
  evidence: Evidence[];       // Accumulated evidence
  reasoning: string[];        // Chain of thought steps
}

export class RLMState {
  private data: RLMStateData;
  private config: RLMEngineConfig;

  constructor(config: RLMEngineConfig) {
    this.config = config;
    this.data = this.initState();
  }

  private initState(): RLMStateData {
    return {
      variables: new Map(),
      chunks: [],
      query: '',
      originalQuery: '',
      depth: 0,
      tokenBudget: this.config.tokenBudget,
      tokensUsed: 0,
      evidence: [],
      reasoning: [],
    };
  }

  /**
   * Initialize state with query and retrieved chunks
   */
  initialize(query: string, chunks: Chunk[], scores: number[]): void {
    this.data.query = query;
    this.data.originalQuery = query;
    this.data.chunks = chunks.map((chunk, i) => ({
      id: chunk.id,
      text: chunk.text,
      score: scores[i] || 0,
      metadata: {
        path: chunk.metadata.path,
        symbol_name: chunk.metadata.symbol_name,
        start_line: chunk.metadata.start_line,
        end_line: chunk.metadata.end_line,
      },
    }));
  }

  /**
   * Get context summary (not full text) for prompt
   */
  getContextSummary(): string {
    const lines = [
      `Context: ${this.data.chunks.length} chunks retrieved`,
      `Total lines: ${this.getTotalLines()}`,
      '',
      'Available chunks:',
    ];

    for (const chunk of this.data.chunks) {
      lines.push(
        `  [${chunk.id}] ${chunk.metadata.path}:${chunk.metadata.start_line}-${chunk.metadata.end_line} ` +
        `(${chunk.metadata.symbol_name}, score: ${chunk.score.toFixed(2)})`
      );
    }

    return lines.join('\n');
  }

  /**
   * Get full context text (for tool inspection, not prompt)
   */
  getFullContext(): string {
    return this.data.chunks
      .map(c => `--- ${c.id} (${c.metadata.path}) ---\n${c.text}`)
      .join('\n\n');
  }

  /**
   * Get context lines by range (for peek_context tool)
   */
  getContextLines(startLine: number, endLine: number): string {
    const fullText = this.getFullContext();
    const lines = fullText.split('\n');
    return lines.slice(startLine, endLine + 1).join('\n');
  }

  /**
   * Search context for pattern (for search_context tool)
   */
  searchContext(pattern: string): Array<{ line: number; text: string; chunkId: string }> {
    const regex = new RegExp(pattern, 'gi');
    const results: Array<{ line: number; text: string; chunkId: string }> = [];

    for (const chunk of this.data.chunks) {
      const lines = chunk.text.split('\n');
      for (let i = 0; i < lines.length; i++) {
        if (regex.test(lines[i])) {
          results.push({
            line: i,
            text: lines[i],
            chunkId: chunk.id,
          });
        }
      }
    }

    return results.slice(0, 20);  // Limit results
  }

  /**
   * Get specific chunk by ID (for sub_query tool)
   */
  getChunk(chunkId: string): ContextChunk | undefined {
    return this.data.chunks.find(c => c.id === chunkId);
  }

  /**
   * Update query for recursion
   */
  setQuery(query: string): void {
    this.data.query = query;
  }

  /**
   * Increment depth for recursion
   */
  incrementDepth(): void {
    this.data.depth++;
  }

  /**
   * Check if can recurse (RLM-05)
   */
  canRecurse(): boolean {
    return this.data.depth < this.config.maxDepth &&
           this.data.tokensUsed < this.data.tokenBudget;
  }

  /**
   * Add evidence
   */
  addEvidence(evidence: Evidence): void {
    this.data.evidence.push(evidence);
  }

  /**
   * Add reasoning step
   */
  addReasoning(step: string): void {
    this.data.reasoning.push(step);
  }

  /**
   * Track token usage
   */
  addTokens(count: number): void {
    this.data.tokensUsed += count;
  }

  /**
   * Set/get variables (REPL pattern)
   */
  setVariable(name: string, value: unknown): void {
    this.data.variables.set(name, value);
  }

  getVariable(name: string): unknown {
    return this.data.variables.get(name);
  }

  // Getters
  get query(): string { return this.data.query; }
  get originalQuery(): string { return this.data.originalQuery; }
  get depth(): number { return this.data.depth; }
  get tokensUsed(): number { return this.data.tokensUsed; }
  get tokenBudget(): number { return this.data.tokenBudget; }
  get evidence(): Evidence[] { return [...this.data.evidence]; }
  get reasoning(): string[] { return [...this.data.reasoning]; }
  get chunks(): ContextChunk[] { return [...this.data.chunks]; }
  get maxDepth(): number { return this.config.maxDepth; }

  private getTotalLines(): number {
    return this.data.chunks.reduce((sum, c) => sum + c.text.split('\n').length, 0);
  }

  /**
   * Reset state for new query
   */
  reset(): void {
    this.data = this.initState();
  }
}
```

Key features:
- REPL-style variable storage
- Context stored externally (not in prompt)
- Tool-accessible context inspection methods
- Recursion tracking with limits (RLM-05)
  </action>
  <verify>npm run build:rlm compiles state.ts</verify>
  <done>REPL-style state management implemented</done>
</task>

<task type="auto">
  <name>Task 3: Create engine module index</name>
  <files>src/rlm/engine/index.ts</files>
  <action>
Create index.ts to export engine types and state:

```typescript
/**
 * RLM Engine Module
 *
 * Recursive reasoning engine with REPL-style state management.
 */

export * from './types.js';
export { RLMState, type RLMStateData } from './state.js';
```

Note: RLMEngine class will be added in Plan 02-02.
  </action>
  <verify>Can import: `import { RLMState, Evidence, RLMResult } from './engine/index.js'`</verify>
  <done>Engine module exports configured</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build:rlm` compiles all engine types
- [ ] RLMState class stores context externally (REPL pattern)
- [ ] State supports variable storage (set/get)
- [ ] Context inspection methods work (getContextLines, searchContext)
- [ ] Recursion limits tracked (depth, tokenBudget)
</verification>

<success_criteria>
- Engine types defined (Evidence, RLMResult, RLMEngineConfig)
- REPL-style state container with external context storage
- Tool-accessible context inspection (peek, search, get chunk)
- Recursion tracking with configurable limits
- Foundation for RLM-01, RLM-03, RLM-05 requirements
</success_criteria>

<output>
After completion, create `.planning/phases/02-rlm-engine-core/02-01-SUMMARY.md`
</output>
