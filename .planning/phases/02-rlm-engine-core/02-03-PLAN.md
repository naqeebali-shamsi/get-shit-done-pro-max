---
phase: 02-rlm-engine-core
plan: 03
type: execute
wave: 2
depends_on: ["02-01"]
files_modified: [src/rlm/evidence/tracker.ts, src/rlm/evidence/confidence.ts, src/rlm/evidence/index.ts]
autonomous: true
---

<objective>
Implement evidence tracking and confidence scoring modules.

Purpose: Enable verification by linking claims to source chunks and computing confidence scores.
Output: Evidence tracker and confidence calculator based on retrieval scores, not verbal confidence.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/02-rlm-engine-core/02-RESEARCH.md

# Types from Plan 02-01
@src/rlm/engine/types.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement evidence tracker</name>
  <files>src/rlm/evidence/tracker.ts</files>
  <action>
Create src/rlm/evidence/ directory and tracker.ts:

```typescript
/**
 * Evidence Tracker
 *
 * Links claims to source chunks and tracks verification status.
 * Core RLM-03 requirement: each claim must reference source chunks.
 */

import type { Evidence, ContextChunk } from '../engine/types.js';

/**
 * Claim extracted from a response
 */
export interface Claim {
  text: string;
  position: number;  // Position in response
}

/**
 * Evidence tracker for an RLM query
 */
export class EvidenceTracker {
  private evidence: Evidence[] = [];
  private chunks: Map<string, ContextChunk> = new Map();

  /**
   * Register available chunks for evidence linking
   */
  registerChunks(chunks: ContextChunk[]): void {
    for (const chunk of chunks) {
      this.chunks.set(chunk.id, chunk);
    }
  }

  /**
   * Add evidence entry
   */
  addEvidence(evidence: Evidence): void {
    this.evidence.push(evidence);
  }

  /**
   * Create evidence from LLM response with cited chunks
   */
  createEvidence(claim: string, chunkIds: string[], retrievalScores: number[]): Evidence {
    // Validate chunk IDs exist
    const validChunks = chunkIds.filter(id => this.chunks.has(id));

    // Calculate confidence based on retrieval scores
    const avgScore = validChunks.length > 0
      ? retrievalScores.reduce((sum, s) => sum + s, 0) / retrievalScores.length
      : 0;

    const evidence: Evidence = {
      claim,
      sourceChunks: validChunks,
      confidence: avgScore,
      verified: false,
    };

    this.evidence.push(evidence);
    return evidence;
  }

  /**
   * Extract claims from a response (simple sentence splitting)
   */
  extractClaims(response: string): Claim[] {
    // Split on sentence boundaries
    const sentences = response
      .split(/(?<=[.!?])\s+/)
      .filter(s => s.trim().length > 10)  // Skip very short fragments
      .map(s => s.trim());

    return sentences.map((text, i) => ({
      text,
      position: i,
    }));
  }

  /**
   * Check if all claims have supporting evidence
   */
  checkCoverage(claims: Claim[]): {
    covered: Claim[];
    uncovered: Claim[];
    coverageRatio: number;
  } {
    const covered: Claim[] = [];
    const uncovered: Claim[] = [];

    for (const claim of claims) {
      const hasEvidence = this.evidence.some(e =>
        e.claim === claim.text && e.sourceChunks.length > 0
      );

      if (hasEvidence) {
        covered.push(claim);
      } else {
        uncovered.push(claim);
      }
    }

    const coverageRatio = claims.length > 0
      ? covered.length / claims.length
      : 1;

    return { covered, uncovered, coverageRatio };
  }

  /**
   * Get evidence for a specific claim
   */
  getEvidenceForClaim(claim: string): Evidence | undefined {
    return this.evidence.find(e => e.claim === claim);
  }

  /**
   * Get all evidence entries
   */
  getAllEvidence(): Evidence[] {
    return [...this.evidence];
  }

  /**
   * Get chunk by ID
   */
  getChunk(chunkId: string): ContextChunk | undefined {
    return this.chunks.get(chunkId);
  }

  /**
   * Mark evidence as verified
   */
  markVerified(claim: string, verified: boolean): void {
    const evidence = this.evidence.find(e => e.claim === claim);
    if (evidence) {
      evidence.verified = verified;
    }
  }

  /**
   * Get verification summary
   */
  getVerificationSummary(): {
    total: number;
    verified: number;
    failed: number;
    pending: number;
  } {
    const verified = this.evidence.filter(e => e.verified).length;
    const pending = this.evidence.filter(e => !e.verified && e.sourceChunks.length > 0).length;
    const failed = this.evidence.filter(e => !e.verified && e.sourceChunks.length === 0).length;

    return {
      total: this.evidence.length,
      verified,
      failed,
      pending,
    };
  }

  /**
   * Clear all evidence
   */
  clear(): void {
    this.evidence = [];
    this.chunks.clear();
  }
}
```

Key features:
- Links claims to source chunks (RLM-03)
- Tracks verification status (RLM-03)
- Simple claim extraction from responses
- Coverage checking for evidence gaps
  </action>
  <verify>npm run build:rlm compiles tracker.ts</verify>
  <done>Evidence tracker implemented</done>
</task>

<task type="auto">
  <name>Task 2: Implement confidence scoring</name>
  <files>src/rlm/evidence/confidence.ts</files>
  <action>
Create confidence.ts implementing scoring based on retrieval scores:

```typescript
/**
 * Confidence Scoring
 *
 * Calculates confidence based on retrieval scores and evidence coverage.
 * Key insight: Don't trust verbal confidence - use retrieval metrics instead.
 */

import type { Evidence, ContextChunk } from '../engine/types.js';

/**
 * Factors contributing to confidence score
 */
export interface ConfidenceFactors {
  retrievalScore: number;      // Average retrieval score of cited chunks
  evidenceCoverage: number;    // Ratio of claims with evidence
  chunkCount: number;          // Number of supporting chunks
  consistencyScore: number;    // Agreement between evidence pieces
}

/**
 * Weights for confidence factors
 */
export interface ConfidenceWeights {
  retrieval: number;
  evidence: number;
  chunkCount: number;
  consistency: number;
}

export const DEFAULT_WEIGHTS: ConfidenceWeights = {
  retrieval: 0.4,      // Retrieval score most important
  evidence: 0.35,      // Evidence coverage second
  chunkCount: 0.1,     // More chunks = more support
  consistency: 0.15,   // Consistency across evidence
};

/**
 * Calculate overall confidence score
 */
export function calculateConfidence(
  factors: ConfidenceFactors,
  weights: ConfidenceWeights = DEFAULT_WEIGHTS
): number {
  // Normalize chunk count factor (1-5 chunks = 0.2-1.0)
  const chunkFactor = Math.min(1, factors.chunkCount * 0.2);

  const score =
    factors.retrievalScore * weights.retrieval +
    factors.evidenceCoverage * weights.evidence +
    chunkFactor * weights.chunkCount +
    factors.consistencyScore * weights.consistency;

  // Clamp to [0, 1]
  return Math.max(0, Math.min(1, score));
}

/**
 * Calculate retrieval score from evidence entries
 */
export function calculateRetrievalScore(evidence: Evidence[]): number {
  if (evidence.length === 0) return 0;

  const scores = evidence
    .filter(e => e.sourceChunks.length > 0)
    .map(e => e.confidence);

  if (scores.length === 0) return 0;

  return scores.reduce((sum, s) => sum + s, 0) / scores.length;
}

/**
 * Calculate evidence coverage (claims backed by chunks)
 */
export function calculateEvidenceCoverage(
  totalClaims: number,
  coveredClaims: number
): number {
  if (totalClaims === 0) return 1;
  return coveredClaims / totalClaims;
}

/**
 * Calculate consistency score between evidence pieces
 */
export function calculateConsistency(
  evidence: Evidence[],
  chunks: Map<string, ContextChunk>
): number {
  if (evidence.length < 2) return 1;  // Single evidence = consistent

  // Check if cited chunks are from related files/symbols
  const paths = new Set<string>();
  const symbols = new Set<string>();

  for (const e of evidence) {
    for (const chunkId of e.sourceChunks) {
      const chunk = chunks.get(chunkId);
      if (chunk) {
        paths.add(chunk.metadata.path);
        if (chunk.metadata.symbol_name) {
          symbols.add(chunk.metadata.symbol_name);
        }
      }
    }
  }

  // More concentrated evidence (fewer unique files/symbols) = higher consistency
  const pathDiversity = paths.size > 0 ? 1 / paths.size : 0;
  const symbolDiversity = symbols.size > 0 ? 1 / symbols.size : 0;

  // Average of path and symbol concentration
  return (pathDiversity + symbolDiversity) / 2;
}

/**
 * Build confidence factors from evidence and chunks
 */
export function buildConfidenceFactors(
  evidence: Evidence[],
  totalClaims: number,
  chunks: Map<string, ContextChunk>
): ConfidenceFactors {
  const coveredClaims = evidence.filter(e => e.sourceChunks.length > 0).length;
  const allChunkIds = evidence.flatMap(e => e.sourceChunks);
  const uniqueChunks = new Set(allChunkIds);

  return {
    retrievalScore: calculateRetrievalScore(evidence),
    evidenceCoverage: calculateEvidenceCoverage(totalClaims, coveredClaims),
    chunkCount: uniqueChunks.size,
    consistencyScore: calculateConsistency(evidence, chunks),
  };
}

/**
 * Get confidence level label
 */
export function getConfidenceLevel(score: number): 'low' | 'medium' | 'high' {
  if (score >= 0.7) return 'high';
  if (score >= 0.4) return 'medium';
  return 'low';
}

/**
 * Confidence report for a query result
 */
export interface ConfidenceReport {
  score: number;
  level: 'low' | 'medium' | 'high';
  factors: ConfidenceFactors;
  warnings: string[];
}

/**
 * Generate confidence report
 */
export function generateConfidenceReport(
  evidence: Evidence[],
  totalClaims: number,
  chunks: Map<string, ContextChunk>,
  weights: ConfidenceWeights = DEFAULT_WEIGHTS
): ConfidenceReport {
  const factors = buildConfidenceFactors(evidence, totalClaims, chunks);
  const score = calculateConfidence(factors, weights);
  const level = getConfidenceLevel(score);

  const warnings: string[] = [];

  if (factors.retrievalScore < 0.5) {
    warnings.push('Low retrieval scores - context may not be relevant');
  }

  if (factors.evidenceCoverage < 0.5) {
    warnings.push('Many claims lack supporting evidence');
  }

  if (factors.chunkCount === 0) {
    warnings.push('No source chunks cited');
  }

  if (factors.consistencyScore < 0.3) {
    warnings.push('Evidence spans many unrelated files - may lack focus');
  }

  return {
    score,
    level,
    factors,
    warnings,
  };
}
```

Key features:
- Confidence based on retrieval scores (not verbal) (RLM-04)
- Evidence coverage factor
- Consistency scoring
- Configurable weights
- Warning generation for low confidence
  </action>
  <verify>npm run build:rlm compiles confidence.ts</verify>
  <done>Confidence scoring implemented</done>
</task>

<task type="auto">
  <name>Task 3: Create evidence module index</name>
  <files>src/rlm/evidence/index.ts</files>
  <action>
Create index.ts to export evidence module:

```typescript
/**
 * RLM Evidence Module
 *
 * Evidence tracking and confidence scoring for RLM results.
 */

export { EvidenceTracker, type Claim } from './tracker.js';
export {
  calculateConfidence,
  calculateRetrievalScore,
  calculateEvidenceCoverage,
  calculateConsistency,
  buildConfidenceFactors,
  getConfidenceLevel,
  generateConfidenceReport,
  DEFAULT_WEIGHTS,
  type ConfidenceFactors,
  type ConfidenceWeights,
  type ConfidenceReport,
} from './confidence.js';
```
  </action>
  <verify>Can import: `import { EvidenceTracker, calculateConfidence } from './evidence/index.js'`</verify>
  <done>Evidence module exports configured</done>
</task>

</tasks>

<verification>
Before declaring plan complete:
- [ ] `npm run build:rlm` compiles all evidence files
- [ ] EvidenceTracker links claims to source chunks
- [ ] Confidence calculated from retrieval scores, not verbal
- [ ] Coverage checking identifies unsupported claims
- [ ] ConfidenceReport generated with warnings
</verification>

<success_criteria>
- Evidence tracking links claims to chunks (RLM-03)
- Confidence scoring based on retrieval metrics (RLM-04)
- Coverage checking for evidence gaps
- Configurable confidence weights
- Foundation for verification loop (Phase 3)
</success_criteria>

<output>
After completion, create `.planning/phases/02-rlm-engine-core/02-03-SUMMARY.md`
</output>
